{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project \n",
    "## Brainster DS x Parkinson's Disease Specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from functools import partial\n",
    "import re\n",
    "import pickle\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, train_test_split, KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path to  User files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_root = \"D:/Brainster/Final Project/ArchivedUsers/ArchivedUsers/\" # change to your path\n",
    "user_fn_list = os.listdir(user_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for read User files\n",
    "#### cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_one_file(fn, root):\n",
    "    out = dict()\n",
    "    with open(root + fn) as f:\n",
    "        for line in f.readlines():\n",
    "            k, v = line.split(\": \")\n",
    "            out[k] = v.strip()\n",
    "            out['ID'] = re.findall(r'_(\\w+)\\.', fn)[0]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read all user files in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_list = list(map(partial(read_one_file, root=user_root), user_fn_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert list to dataframe\n",
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.DataFrame(users_list)\n",
    "users.replace('------', np.nan, inplace=True)\n",
    "users.replace('', np.nan, inplace=True)\n",
    "users['Levadopa'] = users['Levadopa'] == 'True'\n",
    "users['MAOB'] = users['MAOB'] == 'True'\n",
    "users['Parkinsons'] = users['Parkinsons'] == 'True'\n",
    "users['Tremors'] = users['Tremors'] == 'True'\n",
    "users['Other'] = users['Other'] == 'True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for read Tappy files\n",
    "\n",
    "#### cleaning the data and fix corupted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_root = \"D:/Brainster/Final Project/TappyData/TappyData/\" # change to your path\n",
    "keys_fn_list = os.listdir(keys_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_one_key_file(fn, root):\n",
    "    # try:\n",
    "    df = pd.read_csv(root + fn, delimiter='\\t', header=None, on_bad_lines='skip',\n",
    "                         usecols=range(8), low_memory=False)\n",
    "    df.columns = ['ID', 'Date', 'TS', 'Hand', 'HoldTime', 'Direction', 'LatencyTime', 'FlightTime']\n",
    "    df = df[df['ID'].apply(lambda x: len(str(x)) == 10)\n",
    "                   & df['Date'].apply(lambda x: len(str(x)) == 6)\n",
    "                   & df['TS'].apply(lambda x: len(str(x)) == 12)\n",
    "                   & np.in1d(df['Hand'], [\"L\", \"R\", \"S\"])\n",
    "                   & df['HoldTime'].apply(lambda x: re.search(r\"[^\\d.]\", str(x)) is None)\n",
    "                   & np.in1d(df['Direction'], ['LL', 'LR', 'RL', 'RR', 'LS', 'SL', 'RS', 'SR', 'RR'])\n",
    "                   & df['LatencyTime'].apply(lambda x: re.search(r\"[^\\d.]\", str(x)) is None)\n",
    "                   & df['FlightTime'].apply(lambda x: re.search(r\"[^\\d.]\", str(x)) is None)]\n",
    "    df['HoldTime'] = df['HoldTime'].astype(float)\n",
    "    df['LatencyTime'] = df['LatencyTime'].astype(float)\n",
    "    df['FlightTime'] = df['FlightTime'].astype(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read all Tappy files in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_list = list(map(partial(read_one_key_file, root=keys_root), keys_fn_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all Tappy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = pd.concat(keys_list, ignore_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4675453, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys['ID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find users with sufficient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_w_sufficient_data = set((keys.groupby('ID').size() >= 2000).index)\n",
    "user_eligible = set(users[((users['Parkinsons']) & (users['Impact'] == 'Mild') \n",
    "                       | (~users['Parkinsons']))\n",
    "                      & (~users['Levadopa'])]['ID'])\n",
    "user_valid = user_w_sufficient_data.intersection(user_eligible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_keys = keys[(keys['HoldTime'] > 0)\n",
    "                   & (keys['LatencyTime'] > 0)\n",
    "                   & (keys['HoldTime'] < 2000)\n",
    "                   & (keys['LatencyTime'] < 2000)\n",
    "                   & np.in1d(keys['ID'], list(user_valid))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find and remuve duplicates rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated row: 26835\n",
      "Records dropped.The new shape of the DataFrame is: (3662927, 8)\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of duplicated row: {valid_keys.duplicated().sum()}')\n",
    "valid_keys.drop_duplicates()\n",
    "print(f'Records dropped.The new shape of the DataFrame is: {valid_keys.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the DataFrame to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.to_csv('df_user.csv', index=False)\n",
    "valid_keys.to_csv('df_keys.csv', index=False)\n",
    "\n",
    "users.to_pickle('df_user.pkl')\n",
    "valid_keys.to_pickle('df_keys.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
